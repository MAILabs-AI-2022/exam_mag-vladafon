{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Классификатор языков "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import string\r\n",
    "\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Администратор.WI\n",
      "[nltk_data]     N-A4RBFQ3J62N\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "punctuation_chars = string.punctuation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "data_dutch = pd.read_csv('dutch.txt', sep=\" \", header=None)\r\n",
    "data_dutch.columns = [\"words\"]\r\n",
    "\r\n",
    "#preproccesing\r\n",
    "data_dutch[\"words\"] = data_dutch[\"words\"].str.lower()\r\n",
    "\r\n",
    "for char in punctuation_chars:\r\n",
    "    data_dutch[\"words\"] = data_dutch[\"words\"].map(lambda x: x.replace(char,\"\"))\r\n",
    "\r\n",
    "\r\n",
    "dutch_sw = stopwords.words('dutch')\r\n",
    "\r\n",
    "data_dutch = data_dutch[~data_dutch[\"words\"].isin(dutch_sw)]\r\n",
    "\r\n",
    "#Let 0 - dutch, 1 - hungarian, 2 - portugese\r\n",
    "\r\n",
    "data_dutch[\"0\"] = 1\r\n",
    "data_dutch[\"1\"] = 0\r\n",
    "data_dutch[\"2\"] = 0\r\n",
    "print(data_dutch.head())\r\n",
    "print(data_dutch.size)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   words  0  1  2\n",
      "11    we  1  0  0\n",
      "32   jij  1  0  0\n",
      "36  weet  1  0  0\n",
      "42   wel  1  0  0\n",
      "48  goed  1  0  0\n",
      "18088\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "data_hungarian = pd.read_csv('hungarian.txt', sep=\" \", header=None)\r\n",
    "data_hungarian.columns = [\"words\"]\r\n",
    "\r\n",
    "#preproccesing\r\n",
    "data_hungarian[\"words\"] = data_hungarian[\"words\"].str.lower()\r\n",
    "\r\n",
    "for char in punctuation_chars:\r\n",
    "    data_hungarian[\"words\"] = data_hungarian[\"words\"].map(lambda x: x.replace(char,\"\"))\r\n",
    "\r\n",
    "\r\n",
    "hungarian_sw = stopwords.words('hungarian')\r\n",
    "\r\n",
    "data_hungarian = data_hungarian[~data_hungarian[\"words\"].isin(hungarian_sw)]\r\n",
    "\r\n",
    "#Let 0 - dutch, 1 - hungarian, 2 - portugese\r\n",
    "\r\n",
    "data_hungarian[\"0\"] = 0\r\n",
    "data_hungarian[\"1\"] = 1\r\n",
    "data_hungarian[\"2\"] = 0\r\n",
    "print(data_hungarian.head())\r\n",
    "print(data_hungarian.size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      words  0  1  2\n",
      "7        is  0  1  0\n",
      "12       ha  0  1  0\n",
      "23       te  0  1  0\n",
      "31    tudom  0  1  0\n",
      "43  rendben  0  1  0\n",
      "17512\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "data_portuguese = pd.read_csv('portugese.txt', sep=\" \", header=None)\r\n",
    "data_portuguese.columns = [\"words\"]\r\n",
    "\r\n",
    "#preproccesing\r\n",
    "data_portuguese[\"words\"] = data_portuguese[\"words\"].str.lower()\r\n",
    "\r\n",
    "for char in punctuation_chars:\r\n",
    "    data_portuguese[\"words\"] = data_portuguese[\"words\"].map(lambda x: x.replace(char,\"\"))\r\n",
    "\r\n",
    "\r\n",
    "portuguese_sw = stopwords.words('portuguese')\r\n",
    "\r\n",
    "data_portuguese = data_portuguese[~data_portuguese[\"words\"].isin(portuguese_sw)]\r\n",
    "\r\n",
    "#Let 0 - dutch, 1 - hungarian, 2 - portugese\r\n",
    "\r\n",
    "data_portuguese[\"0\"] = 0\r\n",
    "data_portuguese[\"1\"] = 0\r\n",
    "data_portuguese[\"2\"] = 1\r\n",
    "print(data_portuguese.head())\r\n",
    "print(data_portuguese.size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    words  0  1  2\n",
      "5     ser  0  0  1\n",
      "12    ter  0  0  1\n",
      "17  estar  0  0  1\n",
      "20  fazer  0  0  1\n",
      "21  poder  0  0  1\n",
      "19804\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "#concating all together\r\n",
    "\r\n",
    "frames = [data_dutch, data_hungarian,data_portuguese]\r\n",
    "  \r\n",
    "result_df = pd.concat(frames)\r\n",
    "result_df.reset_index(drop=True)\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "result_df = shuffle(result_df).reset_index(drop=True)\r\n",
    "\r\n",
    "result_df[\"words\"].replace('\\d+', '', regex=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0              sujo\n",
       "1                pó\n",
       "2         állítólag\n",
       "3              galo\n",
       "4        velocidade\n",
       "            ...    \n",
       "13846    ministerie\n",
       "13847          vége\n",
       "13848        gyenge\n",
       "13849       místico\n",
       "13850       bewaken\n",
       "Name: words, Length: 13851, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "#converting words to vectors of char\r\n",
    "\r\n",
    "result_df[\"words\"] = result_df[\"words\"].map(lambda x: list(x))\r\n",
    "result_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[s, u, j, o]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[p, ó]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[á, l, l, í, t, ó, l, a, g]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[g, a, l, o]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[v, e, l, o, c, i, d, a, d, e]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            words  0  1  2\n",
       "0                    [s, u, j, o]  0  0  1\n",
       "1                          [p, ó]  0  0  1\n",
       "2     [á, l, l, í, t, ó, l, a, g]  0  1  0\n",
       "3                    [g, a, l, o]  0  0  1\n",
       "4  [v, e, l, o, c, i, d, a, d, e]  0  0  1"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "flat_list = [x for xs in result_df[\"words\"] for x in xs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "#set of unique chars\r\n",
    "chars_set = set(flat_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "len(chars_set)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "chars_dict = {k: v for v, k in enumerate(chars_set)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "chars_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'7': 0,\n",
       " 'r': 1,\n",
       " 'õ': 2,\n",
       " 'í': 3,\n",
       " 'ã': 4,\n",
       " 'y': 5,\n",
       " 'â': 6,\n",
       " 's': 7,\n",
       " 'ï': 8,\n",
       " 'c': 9,\n",
       " 'i': 10,\n",
       " 'ê': 11,\n",
       " 'ő': 12,\n",
       " 't': 13,\n",
       " 'ë': 14,\n",
       " 'n': 15,\n",
       " 'm': 16,\n",
       " 'e': 17,\n",
       " 'ü': 18,\n",
       " 'z': 19,\n",
       " 'è': 20,\n",
       " 'o': 21,\n",
       " 'u': 22,\n",
       " 'b': 23,\n",
       " 'f': 24,\n",
       " 'x': 25,\n",
       " 'g': 26,\n",
       " 'l': 27,\n",
       " 'a': 28,\n",
       " 'h': 29,\n",
       " 'j': 30,\n",
       " 'ó': 31,\n",
       " 'd': 32,\n",
       " 'q': 33,\n",
       " 'ç': 34,\n",
       " 'ű': 35,\n",
       " 'ú': 36,\n",
       " 'v': 37,\n",
       " 'é': 38,\n",
       " 'p': 39,\n",
       " 'k': 40,\n",
       " 'ö': 41,\n",
       " 'á': 42,\n",
       " 'ô': 43,\n",
       " 'w': 44}"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "#функция, которая преобразует слово в вектор по принципу bag-of-words\r\n",
    "def vectorize(chars_list, chars_dict):\r\n",
    "    vec = np.zeros(len(chars_dict)).astype(int)\r\n",
    "\r\n",
    "    for char in chars_list:\r\n",
    "        index = chars_dict[char]\r\n",
    "        vec[index] += 1\r\n",
    "    \r\n",
    "    return vec\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "result_df[\"words\"] = result_df[\"words\"].map(lambda x: vectorize(x,chars_dict))\r\n",
    "result_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  0  1  2\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  0  0  1\n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0  0  1\n",
       "2  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  0  1  0\n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0  0  1\n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...  0  0  1"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "cols = ['0', '1', '2']\r\n",
    "labels = result_df[cols].values.tolist()\r\n",
    "\r\n",
    "data = result_df[\"words\"].values.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "data_train = np.asarray(data_train)\r\n",
    "data_test = np.asarray(data_test)\r\n",
    "labels_train = np.asarray(labels_train)\r\n",
    "labels_test = np.asarray(labels_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "#creating model\r\n",
    "\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(300, input_dim=len(chars_dict), activation='relu'))\r\n",
    "model.add(Dense(100, activation='relu'))\r\n",
    "model.add(Dense(3, activation='softmax'))\r\n",
    "# compile the keras model\r\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "model.fit(data_train, labels_train, epochs=20, batch_size=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "2216/2216 [==============================] - 2s 925us/step - loss: 0.1439 - accuracy: 0.9402\n",
      "Epoch 2/20\n",
      "2216/2216 [==============================] - 2s 925us/step - loss: 0.1317 - accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "2216/2216 [==============================] - 2s 938us/step - loss: 0.1277 - accuracy: 0.9448\n",
      "Epoch 4/20\n",
      "2216/2216 [==============================] - 2s 913us/step - loss: 0.1233 - accuracy: 0.9471\n",
      "Epoch 5/20\n",
      "2216/2216 [==============================] - 2s 853us/step - loss: 0.1190 - accuracy: 0.9494\n",
      "Epoch 6/20\n",
      "2216/2216 [==============================] - 2s 937us/step - loss: 0.1135 - accuracy: 0.9520\n",
      "Epoch 7/20\n",
      "2216/2216 [==============================] - 2s 889us/step - loss: 0.1080 - accuracy: 0.9538\n",
      "Epoch 8/20\n",
      "2216/2216 [==============================] - 2s 905us/step - loss: 0.1040 - accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "2216/2216 [==============================] - 2s 1ms/step - loss: 0.1056 - accuracy: 0.9568\n",
      "Epoch 10/20\n",
      "2216/2216 [==============================] - 2s 869us/step - loss: 0.0992 - accuracy: 0.9597\n",
      "Epoch 11/20\n",
      "2216/2216 [==============================] - 2s 799us/step - loss: 0.0983 - accuracy: 0.9588\n",
      "Epoch 12/20\n",
      "2216/2216 [==============================] - 2s 945us/step - loss: 0.0954 - accuracy: 0.9616\n",
      "Epoch 13/20\n",
      "2216/2216 [==============================] - 2s 828us/step - loss: 0.0949 - accuracy: 0.9606\n",
      "Epoch 14/20\n",
      "2216/2216 [==============================] - 2s 798us/step - loss: 0.0908 - accuracy: 0.9624\n",
      "Epoch 15/20\n",
      "2216/2216 [==============================] - 2s 762us/step - loss: 0.0948 - accuracy: 0.9598\n",
      "Epoch 16/20\n",
      "2216/2216 [==============================] - 2s 768us/step - loss: 0.0882 - accuracy: 0.9625\n",
      "Epoch 17/20\n",
      "2216/2216 [==============================] - 2s 745us/step - loss: 0.0854 - accuracy: 0.9644\n",
      "Epoch 18/20\n",
      "2216/2216 [==============================] - 2s 796us/step - loss: 0.0847 - accuracy: 0.9646\n",
      "Epoch 19/20\n",
      "2216/2216 [==============================] - 2s 757us/step - loss: 0.0842 - accuracy: 0.9641\n",
      "Epoch 20/20\n",
      "2216/2216 [==============================] - 2s 741us/step - loss: 0.0812 - accuracy: 0.9667\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e434fe8790>"
      ]
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "_, accuracy = model.evaluate(np.asarray(data_test), np.asarray(labels_test))\r\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "87/87 [==============================] - 0s 686us/step - loss: 1.1282 - accuracy: 0.8116\n",
      "Accuracy: 81.16\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}